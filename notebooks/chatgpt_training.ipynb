{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37435090",
   "metadata": {},
   "source": [
    "Importar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84736ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv.models import RetinaNet\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e17ec6",
   "metadata": {},
   "source": [
    "Cargar archivo annotations.csv y clases a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer anotaciones\n",
    "df = pd.read_csv(\"annotations.csv\")\n",
    "image_dir = tf.constant(\"/images\") # porque está esperando un tensor\n",
    "\n",
    "# Mapeo de clases a IDs\n",
    "class_mapping = {'monster': 0, 'spell': 1, 'trap': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc831ab",
   "metadata": {},
   "source": [
    "Realizar proceso se data augmentation, para multiplicar artificialmente la diversidad del set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81929f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(row):\n",
    "    # Obtener ruta completa como tensor\n",
    "    img_path = tf.strings.join([image_dir, row['filename']], separator=\"/\")\n",
    "    \n",
    "    # Leer y decodificar imagen\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # o decode_png si son PNG\n",
    "\n",
    "    # Redimensionar y normalizar\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Extraer cajas y etiquetas (si están en el DataFrame)\n",
    "    boxes = row['boxes']  # Debe ser tensor (num_boxes, 4)\n",
    "    classes = row['classes']  # Debe ser tensor (num_boxes,)\n",
    "\n",
    "    return {\n",
    "        \"images\": img,\n",
    "        \"bounding_boxes\": {\n",
    "            \"classes\": classes,\n",
    "            \"boxes\": boxes\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Convertir a tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dict(df))\n",
    "dataset = dataset.map(load_data).batch(8)\n",
    "\n",
    "# Usar augmentation de KerasCV (opcional)\n",
    "augmenter = keras_cv.layers.Augmenter([\n",
    "    keras_cv.layers.RandomFlip(mode=\"horizontal\"),\n",
    "    keras_cv.layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n",
    "])\n",
    "\n",
    "dataset = dataset.map(lambda x: augmenter(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516776ee",
   "metadata": {},
   "source": [
    "Mostrar ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b598da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset.take(1):\n",
    "    keras_cv.visualization.plot_bounding_box_gallery(\n",
    "        images=batch[\"images\"],\n",
    "        value_range=(0, 255),\n",
    "        bounding_boxes=batch[\"bounding_boxes\"],\n",
    "        rows=1,\n",
    "        cols=1,\n",
    "        class_mapping=class_mapping,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
